{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from keras import losses\n",
    "from pandas import read_csv\n",
    "from keras.optimizers import Adam\n",
    "import dateutil\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss=losses.mean_squared_error,\n",
    "              optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions skip to main code\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\t#print(df)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t#print (agg)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "def prepare_data(series, n_test, n_lag, n_seq): #n_test= number of test entries, n_lag number of prev entries analysed, n_seq=number of future predicitons\n",
    "\t# extract raw values\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff_series = difference(raw_values, 1)\n",
    "\tdiff_values = diff_series.values\n",
    "\tdiff_values = diff_values.reshape(len(diff_values), 1)\n",
    "\t# rescale values to -1, 1\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaled_values = scaler.fit_transform(diff_values)\n",
    "\tscaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "\t# transform into supervised learning problem X, y\n",
    "\tsupervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split into train and test sets\n",
    "\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "\treturn scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INVERT TRANSFORMED TO ACTUAL FORM\n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "\t# invert first forecast\n",
    "\tinverted = list()\n",
    "\tinverted.append(forecast[0] + last_ob)\n",
    "\t# propagate difference forecast using inverted first value\n",
    "\tfor i in range(1, len(forecast)):\n",
    "\t\tinverted.append(forecast[i] + inverted[i-1])\n",
    "\treturn inverted\n",
    "\n",
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "\tinverted = list()\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\t# create array from forecast\n",
    "\t\tforecast = np.array(forecasts[i])\n",
    "\t\tforecast = forecast.reshape(1, len(forecast))\n",
    "\t\t# invert scaling\n",
    "\t\tinv_scale = scaler.inverse_transform(forecast)\n",
    "\t\tinv_scale = inv_scale[0, :]\n",
    "\n",
    "\t\t# invert differencing\n",
    "\t\tindex = len(series) - n_test + i - 1\n",
    "\t\tlast_ob = series.values[index][1]\n",
    "\t\t\n",
    "\t\tinv_diff = inverse_difference(last_ob, inv_scale)\n",
    "\t\t# store\n",
    "\t\tinverted.append(inv_diff)\n",
    "\treturn inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch data\n",
    "def getData_nex(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    Close = data.close\n",
    "    data = Close\n",
    "    scaler, train, test=prepare_data(data,1000,7,1)\n",
    "    \n",
    "    xtrain = train[:, 0:7]\n",
    "    ytrain = train[:,7:]\n",
    "    xtest = test[:, 0:7]\n",
    "    ytest = test[:,7:]\n",
    "    X_train = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[1],1))\n",
    "    \n",
    "    X_test = np.reshape(xtest, (xtest.shape[0],xtest.shape[1],1))\n",
    "    return X_train,X_test,ytrain,ytest,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate forecasts\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "\tfor i in range(n_seq):\n",
    "\t\ty_true = np.array([row[i] for row in test])\n",
    "\t\ty_pred = np.array([forecast[i] for forecast in forecasts])\n",
    "\t\tmape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\t\trmse=sqrt(mean_squared_error(y_true,y_pred))\n",
    "\t\tprint('t+%d MAPE: %f' % ((i+1), mape))\n",
    "\t\tprint('t+%d RMSE: %f' % ((i+1), rmse))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "\t# plot the entire dataset in blue\n",
    "\tpyplot.plot(series.values)\n",
    "\t# plot the forecasts in red\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\toff_s = len(series) - n_test + i - 1\n",
    "\t\toff_e = off_s + len(forecasts[i]) + 1\n",
    "\t\txaxis = [x for x in range(off_s, off_e)]\n",
    "\t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
    "\t\tpyplot.plot(xaxis, yaxis, color='red')\n",
    "\t# show the plot\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv('EUR_JPY.csv')\n",
    "new_arr  = data.iloc[-7:,-2:-1].values  #takes last 6 values from db\n",
    "new_val = 129.032 #new value in db, hardcoded for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(new_val):\n",
    "    new_data = np.append(new_arr,new_val) #creates new array\n",
    "    new_df= DataFrame(new_data)\n",
    "    #DATA PREPROCESSING\n",
    "    new_values = new_df.values\n",
    "    diff_series = difference(new_values,1)\n",
    "    diff_values = diff_series.values\n",
    "    diff_values = diff_values.reshape(len(diff_values), 1)\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_values = scaler.fit_transform(diff_values)\n",
    "    scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "    s2s = series_to_supervised(scaled_values,6)\n",
    "    supervised_values = s2s.values\n",
    "#     print(supervised_values)\n",
    "    supervised_values = supervised_values.reshape(1,len(supervised_values[0]),1)\n",
    "    #MAKE PREDICTION USING THE LOADED MODEL\n",
    "    forecasts= loaded_model.predict(supervised_values)\n",
    "#     print (forecasts)\n",
    "    #ADD PREDICTION TO THE LAST VALUE TO OBTAIN THE NEXT VALUE\n",
    "#     print(new_data[-1])\n",
    "    final_prediction = new_data[-1]+forecasts\n",
    "    print(\"predicted drop/rise \"+str(forecasts))\n",
    "    print(\"prediction : \" + str(final_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimish/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted drop/rise [[-0.10624623]]\n",
      "prediction : [[128.92575]]\n"
     ]
    }
   ],
   "source": [
    "make_prediction(new_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
