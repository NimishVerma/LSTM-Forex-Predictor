{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "from keras import losses\n",
    "from pandas import read_csv\n",
    "from keras.optimizers import Adam\n",
    "import dateutil\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(x): #date time parser\n",
    "    return str(dateutil.parser.parse(x).date())+'/' +str(dateutil.parser.parse(x).time())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERT DATA INTO A SUPERVISED DATA FORM\n",
    "Taking sequential series of all 'close' values we append another coloumn with corresponsing  i-1 th value of the same sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions skip to main code\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "def prepare_data(series, n_test, n_lag, n_seq): #n_test= number of test entries, n_lag number of prev entries analysed, n_seq=number of future predicitons\n",
    "\t# extract raw values\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff_series = difference(raw_values, 1)\n",
    "\tdiff_values = diff_series.values\n",
    "\tdiff_values = diff_values.reshape(len(diff_values), 1)\n",
    "\t# rescale values to -1, 1\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaled_values = scaler.fit_transform(diff_values)\n",
    "\tscaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "\t# transform into supervised learning problem X, y\n",
    "\tsupervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split into train and test sets\n",
    "\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "\treturn scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INVERT TRANSFORMED TO ACTUAL FORM\n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "\t# invert first forecast\n",
    "\tinverted = list()\n",
    "\tinverted.append(forecast[0] + last_ob)\n",
    "\t# propagate difference forecast using inverted first value\n",
    "\tfor i in range(1, len(forecast)):\n",
    "\t\tinverted.append(forecast[i] + inverted[i-1])\n",
    "\treturn inverted\n",
    "\n",
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "\tinverted = list()\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\t# create array from forecast\n",
    "\t\tforecast = np.array(forecasts[i])\n",
    "\t\tforecast = forecast.reshape(1, len(forecast))\n",
    "\t\t# invert scaling\n",
    "\t\tinv_scale = scaler.inverse_transform(forecast)\n",
    "\t\tinv_scale = inv_scale[0, :]\n",
    "\n",
    "\t\t# invert differencing\n",
    "\t\tindex = len(series) - n_test + i - 1\n",
    "\t\tlast_ob = series.values[index][1]\n",
    "\t\t\n",
    "\t\tinv_diff = inverse_difference(last_ob, inv_scale)\n",
    "\t\t# store\n",
    "\t\tinverted.append(inv_diff)\n",
    "\treturn inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch data\n",
    "def getData_nex(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    Close = data.close\n",
    "    data = Close\n",
    "    scaler, train, test=prepare_data(data,1000,3,1)\n",
    "    \n",
    "    xtrain = train[:, 0:3]\n",
    "    ytrain = train[:,3:]\n",
    "    xtest = test[:, 0:3]\n",
    "    ytest = test[:,3:]\n",
    "    X_train = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[1],1))\n",
    "    \n",
    "    X_test = np.reshape(xtest, (xtest.shape[0],xtest.shape[1],1))\n",
    "    return X_train,X_test,ytrain,ytest,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate forecasts\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "\tfor i in range(n_seq):\n",
    "\t\ty_true = np.array([row[i] for row in test])\n",
    "\t\ty_pred = np.array([forecast[i] for forecast in forecasts])\n",
    "\t\tmape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\t\trmse=sqrt(mean_squared_error(y_true,y_pred))\n",
    "\t\tprint('t+%d MAPE: %f' % ((i+1), mape))\n",
    "\t\tprint('t+%d RMSE: %f' % ((i+1), rmse))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "\t# plot the entire dataset in blue\n",
    "\tpyplot.plot(series.values)\n",
    "\t# plot the forecasts in red\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\toff_s = len(series) - n_test + i - 1\n",
    "\t\toff_e = off_s + len(forecasts[i]) + 1\n",
    "\t\txaxis = [x for x in range(off_s, off_e)]\n",
    "\t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
    "\t\tpyplot.plot(xaxis, yaxis, color='red')\n",
    "\t# show the plot\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'mean_average_percentage_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2d2f4aff4825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#change loss=losses.mean_squared_error for MSE loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m model.compile(loss=losses.mean_average_percentage_error,\n\u001b[0m\u001b[1;32m     19\u001b[0m               optimizer='adam')\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'mean_average_percentage_error'"
     ]
    }
   ],
   "source": [
    "############################MAIN STARTS HERE##################\n",
    "filename='EUR_JPY.csv'\n",
    "[X_train, X_test, ytrain, ytest,scaler] = getData_nex(filename)\n",
    "\n",
    "input_tensor = Input((3, 1,))# t, t-1 and t-2 as input\n",
    "x = input_tensor\n",
    "rnn_size = 128\n",
    "W_INIT = 'he_normal'\n",
    "for i in range(3):#create 3 lstm layers which return a sequqnce of 32, 32*4, 32*8 resp\n",
    "    x = LSTM(32*2**i,return_sequences=True,\n",
    "                          go_backwards=True,kernel_initializer=W_INIT)(x)\n",
    "x=Dropout(0.25)(x)\n",
    "x=Flatten()(x)\n",
    "x = Dense(1, activation='linear',kernel_initializer='normal')(x) #final output layer\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "adam= Adam(lr=0.001)\n",
    "#change loss=losses.mean_squared_error for MSE loss\n",
    "model.compile(loss=losses.mean_absolute_percentage_error,\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to save model\n",
    "#save model's structure\n",
    "#from keras.utils.vis_utils import plot_model as plot\n",
    "#from IPython.display import Image\n",
    "#plot(model, to_file=\"mBdel.png\", show_shapes=True)\n",
    "#Image('mBdel.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint \n",
    "checkpoint_callback = ModelCheckpoint('stocks_pretrained.hdf5'\n",
    "                                      , monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                      save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "#Fitting Model\n",
    "model.fit(\n",
    "    X_train, ytrain,\n",
    "    batch_size=20, epochs=20,verbose=1,\n",
    "    initial_epoch = 0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#not considering validationdata,might add on later\n",
    "series=pd.read_csv(filename)\n",
    "forecasts = model.predict(X_test)\n",
    "#scaling and inverse helper function\n",
    "forecasts = inverse_transform(series, forecasts, scaler,1000)\n",
    "#actual data to compare results with\n",
    "actual = ytest\n",
    "actual = inverse_transform(series, actual, scaler, 1000)\n",
    "evaluate_forecasts(actual, forecasts, 2,1)\n",
    "#print (series.close.values,forecasts[:5])\n",
    "series=series.close\n",
    "plot_forecasts(series, forecasts, 1000)\n",
    "#saving model if needed for future purposes, coompletely optional rn\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "#print(np.concatenate((forecasts,actual),axis=1))\n",
    "\n",
    "# Predicts t +1 value using t,t-1,t-2. works reasonably with current configs but on trying to predict t+1 and t+2 both using t,t-1,t-2 it gives all increasing predictions and on increasing dropout to 0.5 it gives inverted V shaped predictions, i.e the t+1 value is increasing and t+2 falls.\n",
    "#IMO, single step should be practiced on this particular model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
